{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34734f8f",
   "metadata": {},
   "source": [
    "## 학습/테스트 데이터 세트 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e95848",
   "metadata": {},
   "source": [
    "먼저 테스트 데이터세트를 활용하지 않고 학습(train)데이터 세트로만 학습 후 예측하면 어떤 것이 문제인지를 살펴보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fdd75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145134ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# train 데이터만 로딩\n",
    "X_train_all = iris.data\n",
    "y_train_all = iris.target\n",
    "\n",
    "# 알고리즘 로딩\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 학습수행\n",
    "dt_clf.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6920c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce00a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:1.0000\n"
     ]
    }
   ],
   "source": [
    "# 예측을 수행\n",
    "pred = dt_clf.predict(X_train_all)\n",
    "\n",
    "result_acc = accuracy_score(y_train_all,pred)\n",
    "print('예측 정확도:{0:0.4f}'.format(result_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be1bf4",
   "metadata": {},
   "source": [
    "정확도가 100%이다. 뭔가 이상하다.\n",
    "\n",
    "위의 예측 결과가 100% 정확한 이유는 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문이다. 즉, 모의고사를 이미 한 번 보고 답을 알고 있는 상태에서 모의고사 문제와 똑같은 본고사 문제가 출제됐기 때문이다. 따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용의 테스트 데이터 세트여야 한다. 사이킷런의 train_test_split()를 통해 원본 데이터 세트에서 학습 및 테스트 데이터 세트를 쉽게 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed15be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ce40c",
   "metadata": {},
   "source": [
    "sklearn.model_selection 모듈에서 train_test_split를 로드해본다. train_test_split()는 첫 번째 파라미터로 피처 데이터 세트, 두 번째 파라미터로 레이블 데이터 세트를 입력받는다. 그리고 선택적으로 다음 파라미터를 입력받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf59ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb06e1",
   "metadata": {},
   "source": [
    "* test_size: 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정한다. Default는 0.25, 즉 25%이다. \n",
    "\n",
    "\n",
    "* train_size: 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정한다. test_size parameter를 통상적으로 사용하기 때문에 train_size는 잘 사용되지는 않는다.\n",
    "\n",
    "\n",
    "* random_state: random_state는 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값이다. train_test_split()는 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트용 데이터를 생성한다. 실습용 예제이므로 수행할 때마다 동일한 데이터 세트로 분리하기 위해 random_state를 일정한 숫자 값으로 부여하자.\n",
    "\n",
    "\n",
    "* train_test_split()의 반환값은 튜플 형태이다. 순차적으로 학습용 데이터의 피처 데이터 세트, 테스트용 데이터의 피처 데이터 세트, 학습용 데이터의 레이블 데이터 세트, 테스트용 데이터의 레이블 데이터 세트가 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b10485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## iris 데이터 세트를 train_test_split()을 활용하여 테스트 데이터세트를 0.3\n",
    "## random_state = 121로 변경해서 수행해보자.\n",
    "\n",
    "from sklearn.datasets import load_iris # data\n",
    "from sklearn.model_selection import train_test_split # data 분할\n",
    "from sklearn.tree import DecisionTreeClassifier # 분류기\n",
    "from sklearn.metrics import accuracy_score # 정확도 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e050fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a9f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 세트 만들기\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_ftrs = iris_data.data # X값들 \n",
    "y_target = iris_data.target # y값들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "649d7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아까는 없었던 train_test_split을 적용해보자.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ftrs, y_target,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55986aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 shape: (105, 4)\n",
      "X_test의 shape: (45, 4)\n",
      "y_train의 shape: (105,)\n",
      "y_test의 shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "## 데이터가 제대로 분할되었는지 한 번 확인해보자.\n",
    "print('X_train의 shape:', X_train.shape)\n",
    "print('X_test의 shape:', X_test.shape)\n",
    "print('y_train의 shape:', y_train.shape)\n",
    "print('y_test의 shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7300bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.fit(X_train, y_train) # X_train과 y_train이 학습됨\n",
    "pred = dt_clf.predict(X_test) # X_test를 넣어서 예측값을 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51321ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "print('예측 정확도:',np.round(accuracy_score(y_test,pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd0833",
   "metadata": {},
   "source": [
    "#### 교차 검증\n",
    "\n",
    "앞서 알고리즘을 학습시키는 학습데이터와 이에 대한 예측 성능을 평가하기 위한 별도의 테스트용 데이터가 필요하다고 하였다. 하지만 이 방법 역시 과적합(overfitting)에 취약한 약점을 가질 수 있다.\n",
    "\n",
    "\n",
    "* 과적합이란 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것을 말한다. \n",
    "\n",
    "\n",
    "그런데 고정된 학습 데이터와 테스트 데이터로 평가를 하다보면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델을 유도하는 경향이 생기게 된다. 이러한 문제점을 개선하기 위해 교차 검증을 이용해 더 다양한 학습과 평가를 수행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4e0f9",
   "metadata": {},
   "source": [
    "교차 검증을 좀 더 간략히 설명하자면 본고사를 치르기 전에 모의고사를 여러 번 보는 것이다. 즉, 본 고사가 테스트 데이터 세트에 대해 평가하는 거라면 모의고사는 교차 검증에서 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행하는 것이다. ML은 데이터에 기반한다. 그리고 데이터는 이상치, 분포도, 다양한 속성값, 피처 중요도 등 여러 가지 ML에 영향을 미치는 요소를 가지고 있다. 특정 ML알고리즘에서 최적으로 동작할 수 있도록 데이터를 선별해 학습한다면 실제 데이터 양식과는 많은 차이가 있을 것이고 결국 성능 저하로 이어질 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58711125",
   "metadata": {},
   "source": [
    " * 교차 검증은 이러한 데이터 편중을 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것이다.\n",
    " \n",
    "그리고 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라마터 튜닝 등의 모델 최적화를 더욱 손쉽게 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4689bc",
   "metadata": {},
   "source": [
    "대부분의 ML 모델의 성능 평가는 교차 검증 기반으로 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트에 적용해 평가하는 프로세스이다. ML에 사용되는 데이터 세트를 세분화해서 학습, 검증, 테스트 데이터 세트로 나눌 수 있다. 테스트 데이터 세트 외에 별도의 검증 데이터 세트를 두어서 최종 평가 이전에 학습된 모델을 다양하게 평가하는데 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59f4cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # data\n",
    "from sklearn.model_selection import train_test_split # data 분할\n",
    "from sklearn.tree import DecisionTreeClassifier # 분류기\n",
    "from sklearn.metrics import accuracy_score # 정확도 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afae2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "507bd832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f493758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data #x값\n",
    "label = iris.target #y값\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
    "Kfold = KFold(n_splits=5)\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "516d5f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a793902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i,j in [(1,2),(3,4),(6,7)]:\n",
    "#     print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a44caf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2\n",
       "5                5.4               3.9                1.7               0.4\n",
       "6                4.6               3.4                1.4               0.3\n",
       "7                5.0               3.4                1.5               0.2\n",
       "8                4.4               2.9                1.4               0.2\n",
       "9                4.9               3.1                1.5               0.1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(features, columns=iris_data.feature_names)\n",
    "iris_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33e73866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=label[33:149] #33 ~149\n",
    "test_y = label[0:33] # 0~32\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7509900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 10]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= [1,2,3]\n",
    "x.append(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7f0d4ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 교차 검증 정확도:1.0, 학습데이터 크기:120, 검증데이터 크기30\n",
      "#1 검증 세트의 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "#2 교차 검증 정확도:0.9667, 학습데이터 크기:120, 검증데이터 크기30\n",
      "#2 검증 세트의 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "#3 교차 검증 정확도:0.8667, 학습데이터 크기:120, 검증데이터 크기30\n",
      "#3 검증 세트의 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "#4 교차 검증 정확도:0.9333, 학습데이터 크기:120, 검증데이터 크기30\n",
      "#4 검증 세트의 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#5 교차 검증 정확도:0.7333, 학습데이터 크기:120, 검증데이터 크기30\n",
      "#5 검증 세트의 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ## 평균 검증 정확도 0.9\n"
     ]
    }
   ],
   "source": [
    "# KFold 객체의 split()을 호출하게 되면, fold 별 학습용, 검증용 \n",
    "# row index를 array로 받을 수 있다. \n",
    "\n",
    "features = iris.data #x값\n",
    "label = iris.target #y값\n",
    "Kfold = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, val_index in Kfold.split(features):\n",
    "    X_train, X_val = features[train_index], features[val_index]\n",
    "    y_train, y_val = label[train_index], label[val_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_val)\n",
    "    \n",
    "    result_acc = np.round(accuracy_score(y_val,pred),4)\n",
    "    n_iter = n_iter + 1\n",
    "    \n",
    "    print('#{0} 교차 검증 정확도:{1}, 학습데이터 크기:{2}, 검증데이터 크기{3}'.format(n_iter, result_acc,\n",
    "                                                                X_train.shape[0], X_val.shape[0]))\n",
    "    print('#{0} 검증 세트의 인덱스:{1}'.format(n_iter, val_index))\n",
    "    cv_accuracy.append(result_acc)\n",
    "    \n",
    "#각 교차 검증의 정확도를 평균내보자.\n",
    "print('\\n ## 평균 검증 정확도',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "223aed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
