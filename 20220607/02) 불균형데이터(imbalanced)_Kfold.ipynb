{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f65b2a6",
   "metadata": {},
   "source": [
    "### Stratified K fold :: 층화 K fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5454f7f",
   "metadata": {},
   "source": [
    "* Stratified K 폴드는 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K폴드 방식입니다. 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 말한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9521824",
   "metadata": {},
   "source": [
    "가령 대출 사기 데이터를 예측한다고 가정해보자. 이 데이터 셋은 1억 건이고, 수십 개의 피처와 대출사기 여부를 뜻하는 레이블(대출사기:1, 정상대출:0)로 구성돼 있다. 그런데 대부분의 데이터는 정상 대출일 것이다.그리고 대출 사기가 약 1000건이 있다고 한다면 전체의 0.0001%의 아주 작은 확률로 대출 사기 레이블이 존재한다. 이렇게 작은 비율로 1 레이블 값이 있다면 K 폴드로 랜덤하게 학습 및 테스트 세트의 인덱스를 고르더라도 레이블 값인 0과 1의 비율을 제대로 반영하지 못하는 경우가 쉽게 발생한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f161ede",
   "metadata": {},
   "source": [
    "즉, 레이블 값으로 1이 특정 개별 반복별 학습/테스트 데이터 세트에는 상대적으로 많이 들어 있고, 다른 반복 학습/테스트 데이터 세트에는 그렇지 못한 결과가 발생한다. 대출 사기 레이블이 1인 레코드는 비록 건수는 작지만 알고리즘이 대출 사기를 예측하기 위한 중요한 피처 값을 가지고 있기 때문에 매우 중요한 데이터 세트이다.\n",
    "\n",
    "\n",
    "따라서 원본 데이터와 유사한 대출 사기 레이블 값의 분포를 학습/테스트 세트에도 유지하는 게 매우 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c0dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12253ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df.head()\n",
    "\n",
    "# 각 값의 구성확인\n",
    "iris_df['target'].value_counts()\n",
    "\n",
    "## setosa,virsicolor, virginica 각 품종이 50개씩 존재한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2903453d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.target.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873d28a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## CV:1\n",
      "y_train 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: target, dtype: int64\n",
      "y_val 데이터 분포:\n",
      " 0    50\n",
      "Name: target, dtype: int64\n",
      "## CV:2\n",
      "y_train 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: target, dtype: int64\n",
      "y_val 데이터 분포:\n",
      " 1    50\n",
      "Name: target, dtype: int64\n",
      "## CV:3\n",
      "y_train 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: target, dtype: int64\n",
      "y_val 데이터 분포:\n",
      " 2    50\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# KFold 수행을 해보자. ^^ \n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, val_index in kfold.split(iris_df):\n",
    "    n_iter = n_iter + 1 # n_iter + = 1\n",
    "    y_train = iris_df['target'][train_index]\n",
    "    y_val = iris_df['target'][val_index]\n",
    "    print('## CV:{0}'.format(n_iter))\n",
    "    print('y_train 데이터 분포:\\n', y_train.value_counts())\n",
    "    print('y_val 데이터 분포:\\n', y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9daebaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## CV:1\n",
      "y_train 데이터 분포:\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: target, dtype: int64\n",
      "y_val 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: target, dtype: int64\n",
      "## CV:2\n",
      "y_train 데이터 분포:\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: target, dtype: int64\n",
      "y_val 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: target, dtype: int64\n",
      "## CV:3\n",
      "y_train 데이터 분포:\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: target, dtype: int64\n",
      "y_val 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### 위의 방법에서 데이터가 균일하지 않으므로\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, val_index in skf.split(iris_df, iris_df['target']):\n",
    "    n_iter = n_iter + 1 # n_iter + = 1\n",
    "    y_train = iris_df['target'][train_index]\n",
    "    y_val = iris_df['target'][val_index]\n",
    "    print('## CV:{0}'.format(n_iter))\n",
    "    print('y_train 데이터 분포:\\n', y_train.value_counts())\n",
    "    print('y_val 데이터 분포:\\n', y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692458f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
